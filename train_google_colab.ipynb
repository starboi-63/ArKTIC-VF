{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Remotely on Google Colab\n",
    "\n",
    "Make sure you are connected to an environment with an Nvidia GPU. First, clone the project repository and navigate to the root directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/starboi-63/ArTEMIS.git\n",
    "\n",
    "%cd ArTEMIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Python dependencies from `requirements.txt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the CUDA driver installed on the current compute instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that CUDA is working as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "print(\"PyTorch CUDA version: \", torch.version.cuda)\n",
    "print(\"CUDA available: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Dataset\n",
    "Fetch the correct file from drive and unzip it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "\n",
    "!gdown --id \"1-92uD26anIHLDIGVFuxmT7AlN7idVMkE\" # Vimeo-90k dataset full size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip vimeo_septuplet.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mounting to Drive\n",
    "\n",
    "Mount to Google Drive to save logs and checkpoints in real-time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `/content` to the Python path to import local modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/ArTEMIS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create directories to save logs and model training checkpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "logging_dir = '/content/drive/My Drive/Deep Learning/ArTEMIS/training/tensorboard_logs'\n",
    "checkpoint_dir = '/content/drive/My Drive/Deep Learning/ArTEMIS/training/checkpoints'\n",
    "data_dir = '/content/vimeo_septuplet'\n",
    "\n",
    "if not os.path.exists(logging_dir):\n",
    "    os.makedirs(logging_dir)\n",
    "    print(f\"Created directory at {logging_dir}.\")\n",
    "else:\n",
    "    print(f\"Directory {logging_dir} already exists.\\n\")\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    print(f\"Created directory at {checkpoint_dir}.\")\n",
    "else:\n",
    "    print(f\"Directory {checkpoint_dir} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Board:\n",
    "\n",
    "Run the following cells to launch tensorboard, which helps visualize training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"{logging_dir}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train!\n",
    "\n",
    "### Command-Line Arguments\n",
    "\n",
    "#### Key Arguments\n",
    "- `--model`: Model to train. Default: `ArTEMIS`.\n",
    "- `--dataset`: Dataset to train on. Default: `vimeo90k_septuplet`.\n",
    "- `--data_root`: Path to the dataset. Default: `/content/drive/My Drive/Deep Learning/ArTEMIS/vimeo_septuplet`.\n",
    "- `--checkpoint_dir`: Directory saving intermediate model states. Default: `/content/drive/My Drive/Deep Learning/ArTEMIS/training/`.\n",
    "- `--log_dir`: Directory saving TensorBoard logs. Default: `/content/drive/My Drive/Deep Learning/ArTEMIS/training/logs`.\n",
    "\n",
    "#### Model Parameters\n",
    "- `--nbr_frame`: Number of input frames to consider. Default: `4`.\n",
    "- `--joinType`: Type of join operation. Default: `concat`. Choices: `concat`, `add`, `none`.\n",
    "- `--kernel_size`: Kernel size for the convolutional layers. Default: `5`.\n",
    "- `--dilation`: Dilation factor for the convolutional layers. Default: `1`.\n",
    "- `--num_outputs`: Number of interpolated output frames. Default: `3`.\n",
    "\n",
    "#### Learning Parameters\n",
    "- `--loss`: Loss function to use. Default: `1*L1`.\n",
    "- `--lr`: Learning rate. Default: `2e-4`.\n",
    "- `--beta1`: Beta1 for Adam optimizer. Default: `0.9`.\n",
    "- `--beta2`: Beta2 for Adam optimizer. Default: `0.999`.\n",
    "- `--batch_size`: Batch size. Default: `4`.\n",
    "- `--test_batch_size`: Test batch size. Default: `12`.\n",
    "- `--start_epoch`: Start epoch. Default: `0`.\n",
    "- `--max_epoch`: Maximum number of epochs. Default: `100`.\n",
    "- `--resume`: Resume training. Default: `False`.\n",
    "- `--resume_exp`: Resume experiment. Default: `None`.\n",
    "- `--load_from`: Load from a checkpoint. Default: `checkpoints/ArTEMIS/model_best.pth`.\n",
    "- `--pretrained`: Load from a pretrained model. Default: `None`.\n",
    "\n",
    "#### Miscellaneous\n",
    "- `--exp_name`: Experiment name. Default: `exp`.\n",
    "- `--log_iter`: Log iteration. Default: `100`.\n",
    "- `--num_gpu`: Number of GPUs. Default: `1`.\n",
    "- `--random_seed`: Random seed. Default: `103`.\n",
    "- `--num_workers`: Number of workers. Default: `1`.\n",
    "- `--val_freq`: Validation frequency. Default: `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --model ArTEMIS --dataset vimeo90K_septuplet --data_root \"{data_dir}\" --log_dir \"{logging_dir}\" --checkpoint_dir \"{checkpoint_dir}\" --bath_size 4"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
